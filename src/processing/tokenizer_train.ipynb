{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, decoders, trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ahc_PV2F4WxX"
   },
   "outputs": [],
   "source": [
    "def dump_jsonl(data, output_path, append=False):\n",
    "    mode = \"a+\" if append else \"w\"\n",
    "    with open(output_path, mode, encoding=\"utf-8\") as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + \"\\n\")\n",
    "\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    data = []\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip(\"\\n|\\r\")))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace/TFTrainer/')\n",
    "\n",
    "vocab_size = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoCW3M3_HeeV"
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    text = re.sub(r\" {2,}\", r\" \", text)\n",
    "    text = repeat_normalize(text, 3)\n",
    "    text = re.sub(r\"(.{3,}?)\\1+\", r\"\\1\", text)\n",
    "    text = re.sub(r\"[^ ㄱ-ㅎㅏ-ㅣ가-힣A-Za-z0-9]\", r\"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-kkkdzn642YB"
   },
   "outputs": [],
   "source": [
    "data_json = load_jsonl('category.json')\n",
    "\n",
    "data_txt = []\n",
    "for sample in data_json:\n",
    "    data_txt.append(sample['content'].strip())\n",
    "\n",
    "# processing\n",
    "\n",
    "with open(\"tokenizer_data.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for line in data_txt:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1강소기업의 기술독립 전쟁1 에버켐텍은 2019년 친환경 식품포장재를 개발했다 식품의 부패를 방지하기 위해 산소 차단 기능이 적용된 포장재는 이전까지 일본산 소재인 에틸렌비닐알코올로만 만들어졌다 에버켐텍은 천연 단백질을 이용한 신소재로 일본의 식품포장재 시장 독점 구조를 깬 셈이다 에버켐텍이 소재부품장비 강소기업으로 평가받는 이유다2 2001년 설립된 영창케미칼은 일본의 3대 수출규제 품목 중 하나였던 포토레지스트 소재 국산화를 선도했다 반도체 공정의 필수 소재인 포토레지스트는 빛으로 회로 모양을 찍어내는 작업을 할 때 웨이퍼 위에 균일하게 도포되는 액체를 말한다 영창케미칼의 포토레지스트는 경쟁력을 인정받아 현재 삼성전자 SK하이닉스 등 국내 반도체 회사에 공급된다일본 경제산업성이 2019년 7월 고순도 불화수소 플루오린폴리이미드 포토레지스트에 대한 수출규제를 시작하면서 촉발된 소부장 기술전쟁이 2년째를 맞는다 정부는 소부장 기업들이 혁신과 정부 지원정책이 맞물려 기술 자립도가 높아졌다고 평가한다 100대 핵심 품목 대일 의존도 급감중소벤처기업부와 산업통상자원부에 따르면 최근 2년 동안 소부장 관련 100대 핵심 품목에 대한 대일 의존도는 줄고 소부장 기업의 매출은 20 넘게 증가했다 중기부가 선정한 소부장 강소기업100에 포함돼 있는 에버켐텍과 영창케미칼 등의 성과를 보면 일본의 수출규제가 소부장 기업들이 성장하는 계기가 된 셈이다소부장 기술독립의 성과는 양과 질적인 면에서 함께 나타나고 있다 시가총액이 1조 원 이 넘는 소부장 관련 중소중견기업 수는 2019년 13개에서 올해 31개로 늘었다소부장 생태계 내에서 대기업과 중소기업 간 협업 사례도 늘었다 중기부에 따르면 대기업은 생산 라인을 개방해 중소기업이 신규 기술을 검증받을 수 있도록 했다 그러면서 대기업은 중소기업이 개발한 소재를 공급받고 있다 이에 따라 지난해 1분기 소부장 상장기업의 총매출액은 2019년 1분기 대비 201 증가했다 이는 상장기업 전체 평균 매출액 증가율보다 크게 높은 것이다 소부장 히든 챔피언 나오는 생태계중기부는 소부장 히든 챔피언을 만들기 위해 관련 지원에 속도를 내고 있다 소부장 전문기업 육성 생태계를 조성하기 위해 스타트업100강소기업100으뜸기업100으로 이어지는 성장 사다리를 만들겠다는 것이다 이를 위해 지난해 강소기업 100곳을 선정한 데 이어 올해 20곳을 추가로 선정한다 기존 반도체 디스플레이 등에 더해 바이오 환경에너지 소프트웨어통신 등 3대 분야를 추가했다 선정된 기업은 최대 5년 동안 투자 융자 보증 연구인력 등 특화된 사업을 패키지로 지원받는다 그동안 선정된 강소기업 100곳에는 기업당 30억 원 규모로 총 3016억 원이 지원됐다',\n",
       " '서창호 KAIST 전기전자공학부 교수가 국제전기전자공학회 정보이론학회에서 수여하는 제임스 매시 연구교육상을 받았다 이 상은 박사 학위를 받은 후 10년 이내 젊은 학자 중 연구 기여도가 높고 혁신적인 교수법을 개발한 학자를 심사해 수여한다 수상자에게는 상패와 1000달러의 상금이 수여된다 서 교수는 정보이론과 인공지능 분야 전문가다 현재는 신뢰할 수 있는 AI를 개발하는 연구를 진행하고 있다 KAIST에 따르면 한국 대학 소속으로 이 상을 받은 것은 서 교수가 최초다',\n",
       " '손정의 일본 소프트뱅크 회장의 비전펀드가 중국발 악재에 막대한 손실을 떠안게 됐다 이 펀드가 투자한 중국 최대 승차 공유 기업 디디추싱이 중국 정부의 규제로 최근 주가가 폭락했기 때문이다25일 영국 파이낸셜타임스는 비전펀드가 디디추싱 사태로 40억달러의 적자를 보고 있다고 보도했다 비전펀드는 디디추싱의 최대주주로 지난 2019년 118억달러를 투자해 디디추싱 지분 201를 확보했다 하지만 뉴욕 증시에 상장한 디디추싱의 주가가 지난 23일 전날 대비 21 하락한 806달러에 마감하면서 이 지분의 가치는 78억달러 수준으로 급감했다 당초 비전펀드가 투입한 투자금 대비 34가량 폭락한 것이다앞서 디디추싱은 중국 당국의 반대에도 뉴욕 증시 상장을 강행했다 이에 대해 중국 정부는 디디추싱이 핵심 데이터를 유출할 수 있다며 중국 내 모든 앱장터에서 디디추싱을 삭제하도록 명령했다 시장 퇴출 위기에 직면하며 디디추싱의 주가는 이달에만 43 급락했다FT는 투자 포트폴리오의 25 이상이 중국 빅테크인 비전펀드는 중국발 기술기업 규제에 무방비로 노출된 상태라고 평가했다 비전펀드가 투자한 다른 중국 IT기업들도 압력에서 자유롭지 못하다는 것이다 실제로 비전펀드가 투자한 킵이라는 건강 앱은 중국 당국이 자국 기업의 해외 상장 절차를 어렵게 만들면서 미국 상장을 포기했다',\n",
       " '장병규 의장 IPO 기자간담회크래프톤 IPO 온라인 간담회에서 장병규 크래프톤 의장이 질문에 답변하고 있다크래프톤다음 달 상장을 앞둔 게임 업체 크래프톤의 장병규 의장이 26일 간담회를 열고 상장을 통해 확보한 자금의 70를 인수합병에 쓰고 나머지 30는 인도중동아프리카 등 신시장 발굴과 고성능 장비 확충에 쏟아붓겠다고 밝혔다 상장 이후 더욱 공격적으로 세계 시장 진출에 나서겠다는 것이다장 의장은 이어 크래프톤에는 누구도 가지 않는 길을 가는 똘끼 유전자가 있다면서 글로벌에 도전하는 게 크래프톤의 색깔이라고 말했다 그는 또 투자설명회 과정에서 해외 투자자들로부터 크래프톤 때문에 처음으로 한국 기업에 투자를 검토하고 있다는 말을 들었다며 성공적인 상장을 자신했다크래프톤은 상장 추진 과정에서 희망 공모가가 지나치게 높다는 논란이 일기도 했다 결국 당초 45만800055만7000원이던 공모가를 40만49만8000원으로 낮췄다 장 의장은 삼성전자도 한국 시장만 보면 지금과 같은 시가총액이 안 나올 것이라며 크래프톤에 대한 투자는 글로벌 게임 시장에 쉽게 투자할 수 있는 방법이라고 봐야 한다고 말했다 크래프톤의 매출 대부분이 삼성전자처럼 글로벌 시장에서 나오고 있는 만큼 투자 가치가 높다는 것이다 크래프톤은 오는 27일 공모가를 확정하고 다음 달 23일 이틀에 걸쳐 일반 청약을 받는다',\n",
       " 'LG디스플레이가 ESG 경영 강화 목적으로 한국전력의 녹색프리미엄 제도를 활용해 태양광풍력수력 등 신재생 에너지로 생산한 572기가와트시의 전력을 구매했다고 26일 밝혔다 녹색프리미엄은 전기 소비자가 추가 요금을 지불하고 신재생 에너지 사용확인서를 받는 제도다 이에 따라 LG디스플레이는 국내 사업장의 모든 사무동과 마곡 연구개발동 일부 생산현장에서 사용하는 전력을 100 신재생 에너지로 대체할 계획이다',\n",
       " '고평가 논란 크래프톤 비전 발표내달 IPO예상 시총 최대 24조똘끼 DNA로 기회 올 때마다 도전26일 크래프톤 IPO 간담회에서 장병규 의장이 미래 전략에 대해 설명하고 있다다음 달 10일 기업공개를 앞둔 크래프톤이 지식재산을 핵심 성장전략으로 꼽는 IP 명가 비전을 공개했다 최근 불거진 기업가치 고평가 논란을 불식시킬 수 있을지 관심을 모은다크래프톤은 26일 간담회를 열고 상장에 따른 성장 전략과 비전을 발표했다 김창한 크래프톤 대표는 게임을 통해 탄생한 강력한 IP를 다양한 미디어에 확장하고 새로운 IP를 지속해서 만들겠다고 말했다IPO 준비 과정에서 크래프톤은 월트디즈니를 비교 기업군으로 집어넣는 등 기업가치를 지나치게 높게 평가했다는 논란에 휩싸였다 성공한 IP가 플레이어 언노운스 배틀그라운드 하나 뿐인데 실적이 더 좋은 다른 게임회사보다 몸값이 높은 게 타당하냐는 게 핵심이다 실제 지난달 16일 크래프톤이 제출한 최초 증권신고서 기준 예상 시가총액은 23조28조원으로 넥슨 엔씨소프트 등 국내 경쟁사를 웃돌았다 이후 정정신고서를 제출하면서 몸값을 낮췄다 현재 크래프톤의 희망공모가 기준 예상 시총은 약 19조24조원이다김창한 대표는 이날 간담회에서 무엇이 크래프톤을 다른 게임사와 다르게 만드는지에 대해 상당 시간을 할애해 설명했다펍지는 통상 배그로 불린다 2017년 당시 마이너 장르였던 배틀 로얄 게임을 선보여 인기를 끌었다 누적 7500만장 이상이 팔려 역사상 가장 많이 팔린 게임 5위에 오르기도했다 모바일 버전은 100여개국 다운로드 1위를 기록했다 김 대표는 게임 하나로 올린 성과가 아니라고 했다 즉 서비스형 게임이기 때문에 업데이트를 통해 계속 펍지 IP에 속하는 새로운 게임을 출시한 결과이고 앞으로도 그럴 것이란 의미다크래프톤은 기존 펍지 IP를 애니메이션영화드라마 등으로 확장하는 것뿐 아니라 새로운 IP를 만들어 나갈 계획이라고 했다 창업자인 장병규 크래프톤 이사회 의장은 게임을 다양한 미디어로 확장변주하는 게 고객이 원하는 방향이라며 그래야 지속가능한 회사로 만들 수 있다고 말했다 장 의장은 우리가 지금까지 선택해온 길을 보면 똘끼 DNA를 가지고 있다고 느낄 수 있다며 우리는 기회가 올 때마다 도전하는 회사라고 강조했다',\n",
       " '카이스트 전기전자공학부 서창호 교수가 박사학위 취득 후 10년 이내 젊은 학자에게 수여하는 국제전기전자공학회 정보이론 소사이어티의 제임스 매시 연구교육상을 받았다 26일 카이스트에 따르면 미국 대학 소속이 아닌 교수가 이 상을 받기는 처음이다서 교수는 정보이론인공지능 분야 연구자로 현재 신뢰할 수 있는 AI 개발을 진행 중이다',\n",
       " '8월 23일 일반청약 간담회 열어고평가 논란 등 시장 우려에 조목조목 반박장병규 크래프톤 이사회 의장이 26일 온라인으로 진행한 기업공개 간담회에서 발언하고 있다 크래프톤 제공크래프톤에 투자하는 것은 글로벌 게임시장에 접근할 수 있는 투자가 아닌가 싶다장병규 크래프톤 이사회 의장은 26일 회사의 잠재성장성과 투자성에 대해 삼성전자도 한국 시장만 봤다면 그런 시가 총액은 안 나왔을 것이라며 이렇게 자신했다올해 최대 기업공개로 주목받는 크래프톤은 글로벌 히트작인 배틀그라운드의 제작사다 2017년 출시된 배틀그라운드는 현재까지 7500만 장 이상 판매되면서 역사상 가장 많이 팔린 게임 5위에 올랐다 특히 2018년 선보인 배틀그라운드 모바일은 글로벌 다운로드 수 10억 건을 돌파하면서 전 세계 100개국에서 모바일 게임 순위 1위를 기록했다 이를 감안이라도 하듯 장 의장도 이날 열린 온라인 간담회에서 크래프톤 때문에 한국 상장사에 대한 투자를 처음으로 검토하고 있다는 투자자도 있어 감회가 새로웠다고 전했다 크래프톤은 앞서 희망 공모가 산정 과정에서 고평가 논란이 불거진 바 있다전 세계 100개국에서 1위 게임전 세계 기관투자자 주목하고 있다크래프톤은 이번 간담회에서 회사의 미래 성장성과 IPO 이후 투자계획 등에 대해 집중적으로 설명했다 다음 달 23일 일반 청약을 앞둔 크래프톤은 27일까지 기관 투자자 수요예측을 마감하고 공모가를 확정한다 공모 희망가는 40만49만8000원이다 공모가 상단을 기준으로 공모 금액은 4조3098억 원 상장 후 시가총액은 24조3512억 원이다 당초 크래프톤은 공모 희망가를 45만800055만7000원으로 제시했다가 금융감독원의 증권신고서 정정 요구로 5만 원가량 낮췄다세간에서 빚어진 공모가 고평가 논란에 대해 배동근 크래프톤 최고재무관리자는 수요 예측이 내일까지 진행되지만 전 세계 기관투자자들로부터 가치를 인정받고 흥행 중이라고 자신있게 말씀드릴 수 있다고 했다배틀그라운드원 히트 원더 높은 중국 의존도 지적에 9월부터 후속작 출시IPO를 앞두고 일각에서 나온 우려에 대해서도 조목조목 반박했다 이 가운데 회사 매출의 80 이상을 배틀그라운드 모바일에서만 가져간다는 지적은 꾸준하게 제기됐다 이에 대해 김창한 크래프톤 대표는 배틀그라운드의 테이트가 9월 중 글로벌 출시를 목표로 하고 있다며 배틀그라운드의 세계관이 접목된 공포 장르 더 칼리스토 프로토콜은 내년 여름 출시할 것이라고 테이트는 이미 사전예약만으로 전 세계 2500만 명의 이용자를 확보한 상태다회사 전체 매출의 70 이상을 중국에서 가져온다는 부분도 위험 요소로 꼽힌다 이와 관련 배 CFO는 이는 우리 게임의 유통사의 위치가 아시아에 있기 때문에 의존도가 높은 것으로 보이는 것이라고 말했다이어 급성장 중인 인도 시장에서의 크래프톤 활약상도 소개했다 2020년 1월 크래프톤은 텐센트를 통해 인도에 게임을 출시했다가 중국과 인도의 국경분쟁의 여파로 그해 10월 서비스가 종료된 바 있다 김 대표는 9개월 만에 다시 출시했는데 다운로드 4000만 건 월 이용자는 1600만 명에 이를 정도로 기존 수준을 빠르게 회복했다며 인도에서 성공한 게임이 파키스탄 중동 아프리카까지 흥행하는데 이미 인도에서는 배틀그라운드가 국민 게임이라고 설명했다크래프톤은 공모 자금의 70를 국내외 기업의 인수합병에 활용하겠다는 계획을 밝혔다 배 CFO는 2년 전부터 전 세계의 잠재력 있는 지식재산권과 개발사들과 교류해왔다며 크래프톤이 가진 IP에 대해 글로벌 개발자들이 리스펙트하고 있는 만큼 MA도 잘할 수 있을 것이라고 내다봤다',\n",
       " '교육부 교육회복 방안 발표방과후방학중 맞춤형 지도수석교사 등이 학습 컨설팅초중고 학습심리 복합지원두드림학교 6000개교로 확대인력 확보 각 교육청에 넘기고학생 선정 지역별 편차 우려도교육당국이 코로나19 이전 수준으로 학생들의 기초학력을 회복시키겠다는 목표 아래 대대적인 교과 보충수업 지원  학습 지도 프로그램을 내놨다 교사와 예비 교원들을 동원해 방과 후 수업에 나서는 건데 감염병이 불러온 사실상 학교 과외 또는 공적 과외라는 이야기가 나온다 코로나19로 심각해진 기초학력을 회복시키겠다는 방향은 맞지만 교원 인력 충원 방법 수혜 학생 선정 방식 등이 불분명해 현장에서 효과적으로 작동할 수 있을지 미지수다유은혜 사회부총리 겸 교육부 장관이 29일 오전 서울 종로구 정부서울청사 합동브리핑실에서 조희연 서울시교육감 이재정 경기도교육감 등이 참석한 가운데 코로나19 학습결손 해소를 위한 교육회복 종합방안을 발표하고 있다 29일 유은혜 사회부총리 겸 교육부 장관은 조희연 서울시교육감 도성훈 인천시교육감 이재정 경기도교육감과 함께 정부서울청사에서 코로나19 장기화에 따른 교육회복 종합방안을 발표했다 지난해 국가수준 학업성취도 평가에서 중고생의 수학 기초학력 미달이 13를 넘어 역대 최대치를 기록하는 등 코로나19발 학력저하가 공식적으로 확인되면서 교육부가 학습 결손 대책을 내놓겠다고 한지 두 달여 만이다이번 방안의 핵심은 기초학력이 떨어지는 학생을 소규모로 별도 지도한다는 것이다 교육부는 일선 학교가 2학기부터 관찰상담 인공지능 학습진단 정서행동 특성검사 등을 활용해 학생들의 결손을 종합진단하고 필요한 회복 프로그램을 지원하도록 했다 학습 도움닫기 프로그램은 교사가 방과 후나 방학 중에 학습 결손이 있는 학생 35명을 집중 지도한다 수강료는 정부 예산 5700억 원을 통해 178만여 명에게 전액 지원한다 올해엔 2200억 원을 들여 69만 명을 지원하고 내년엔 3500억 원을 지원해 109만 명이 참여할 수 있도록 했다 전국 초중고교생 대비 올해는 129 내년엔 205에 해당한다교육당국은 2022년까지 교육 회복 프로그램에 참여할 수 있는 학생 수를 약 203만 명으로 추산한다 초등학생 102만 명 중학생 51만 명 고등학생 50만 명이 혜택을 볼 것으로 예상하고 있다 이는 지난해 국가수준 학업성취도 평가에서 기초학력에 미달하는 1수준 비율의 36배로 추정되는 규모다교육부 관계자는 기초학력이 떨어지는 학생 외에도 중위권에서 학습 보충이 필요하다고 진단된 학생 희망하는 학생들을 대상으로 지원할 계획이라고 말했다문제는 교육 회복 프로그램에 나설 교원 인력 확보 부분이다 교육부는 교사 확보 방법에 대해 교육청과 각 학교에 공을 넘긴 상황이다 교사로서는 등교와 원격수업이 병행되는 데다 방역으로 업무 부담이 가중되고 있는 가운데 별도 보충 수업까지 맡아야 하는 부담이 커진다 이에 대해 조성철 한국교원단체총연합회 대변인은 교사가 학생 교육활동에 전념하도록 획기적인 행정업무 경감이 요구된다고 지적했다보충 수업에 참여할 학생 선정 문제도 불명확해 학교별지역별로 차이가 날 수 있다는 우려도 나온다 일정한 기준이 있는 것이 아니라 교사 진단과 추천 희망 학생을 대상으로 하기 때문에 교사에 따라 보충 수업 대상 여부가 달라질 수 있다 교육부 관계자는 시도 교육청에서 자체 계획을 수립할 때 그런 사항을 포함해 사각지대가 발생하지 않도록 요청과 협조 당부를 철저히 하도록 하겠다고 말했다',\n",
       " '롯데건설 손승익 팀장과 율하모니 이윤정 대표가 업무협약을 체결 후 기념 촬영하고 있다 롯데건설이 공공지원 민간임대주택 입주민을 위한 서비스 다각화에 나선다고 29일 밝혔다롯데건설은 민간임대주택 입주민을 대상으로 교육서비스 제공을 위해 지난 16일 사회적기업 율하모니와의 업무협약을 체결했다 이번 협약을 통해 율하모니가 보유한 전문 강사 인력의 체계적인 교육 커리큘럼이 단지에 적용될 예정이다 그린카와 민간임대주택 입주민 대상 세차 서비스 제공 관련 업무협약도 같은 날 이뤄졌다 협약식은 롯데건설 정영광 상무와 그린카 김경봉 대표가 참석한 가운데 진행됐다']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_txt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAlRbHul7TZ4",
    "outputId": "1a1c971d-474d-40bc-fccb-d3d6c28780b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>',\n",
      " '<unk>',\n",
      " '<cls>',\n",
      " '<sep>',\n",
      " '<mask>',\n",
      " '<bos>',\n",
      " '<eos>',\n",
      " '<tsep>',\n",
      " '<unk0>',\n",
      " '<unk1>',\n",
      " '<unk2>',\n",
      " '<unk3>',\n",
      " '<unk4>',\n",
      " '<unk5>',\n",
      " '<unk6>',\n",
      " '<unk7>',\n",
      " '<unk8>',\n",
      " '<unk9>',\n",
      " '<unused0>',\n",
      " '<unused1>',\n",
      " '<unused2>',\n",
      " '<unused3>',\n",
      " '<unused4>',\n",
      " '<unused5>',\n",
      " '<unused6>',\n",
      " '<unused7>',\n",
      " '<unused8>',\n",
      " '<unused9>',\n",
      " '<unused10>',\n",
      " '<unused11>',\n",
      " '<unused12>',\n",
      " '<unused13>',\n",
      " '<unused14>',\n",
      " '<unused15>',\n",
      " '<unused16>',\n",
      " '<unused17>',\n",
      " '<unused18>',\n",
      " '<unused19>',\n",
      " '<unused20>',\n",
      " '<unused21>',\n",
      " '<unused22>',\n",
      " '<unused23>',\n",
      " '<unused24>',\n",
      " '<unused25>',\n",
      " '<unused26>',\n",
      " '<unused27>',\n",
      " '<unused28>',\n",
      " '<unused29>',\n",
      " '<unused30>',\n",
      " '<unused31>',\n",
      " '<unused32>',\n",
      " '<unused33>',\n",
      " '<unused34>',\n",
      " '<unused35>',\n",
      " '<unused36>',\n",
      " '<unused37>',\n",
      " '<unused38>',\n",
      " '<unused39>',\n",
      " '<unused40>',\n",
      " '<unused41>',\n",
      " '<unused42>',\n",
      " '<unused43>',\n",
      " '<unused44>',\n",
      " '<unused45>',\n",
      " '<unused46>',\n",
      " '<unused47>',\n",
      " '<unused48>',\n",
      " '<unused49>']\n"
     ]
    }
   ],
   "source": [
    "user_defined_symbols = [\"<pad>\", \"<unk>\", \"<cls>\", \"<sep>\", \"<mask>\", \"<bos>\", \"<eos>\", \"<tsep>\", \"<unk0>\", \"<unk1>\", \"<unk2>\", \"<unk3>\", \"<unk4>\", \"<unk5>\", \"<unk6>\", \"<unk7>\", \"<unk8>\", \"<unk9>\"]\n",
    "unused_token_num = 100\n",
    "unused_list = [f\"<unused{i}>\" for i in range(50)]\n",
    "user_defined_symbols += unused_list\n",
    "\n",
    "pprint(user_defined_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M78kc0QyHjW6"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Mde3nij1HlYo"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.normalizer = normalizers.NFKC()\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Metaspace()])\n",
    "tokenizer.decoders = decoders.Metaspace()\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=vocab_size, \n",
    "    show_progress=True,\n",
    "    special_tokens=user_defined_symbols,\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(data_txt, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0L6QwzpGQWZP",
    "outputId": "4447154f-83bb-4279-a01d-0ea1f087d46b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp/vocab.json', 'temp/merges.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir temp\n",
    "tokenizer.model.save(\"temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETFAiEUiHgrG"
   },
   "source": [
    "# save according to form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8RmIRpxgnfJ",
    "outputId": "d31adf46-3539-47de-ea74-6e126751e78e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file temp/config.json not found\n",
      "file temp/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_for_load = GPT2TokenizerFast.from_pretrained(\"temp\")  # 로드\n",
    "\n",
    "tokenizer_for_load.pad_token = \"<pad>\"\n",
    "tokenizer_for_load.unk_token = \"<unk>\"\n",
    "tokenizer_for_load.cls_token = \"<cls>\"\n",
    "tokenizer_for_load.sep_token = \"<sep>\"\n",
    "tokenizer_for_load.mask_token = \"<mask>\"\n",
    "tokenizer_for_load.bos_token = \"<bos>\"\n",
    "tokenizer_for_load.eos_token = \"<eos>\"\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': user_defined_symbols}\n",
    "tokenizer_for_load.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "tokenizer_for_load.save_pretrained(\"tokenizer\", legacy_format=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in `tokenizer.json`  \n",
    "```json\n",
    "    \"normalizer\": {\n",
    "        \"type\": \"Sequence\",\n",
    "        \"normalizers\": [\n",
    "            {\n",
    "                \"type\": \"NFKC\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"BertNormalizer\",\n",
    "                \"clean_text\": false,\n",
    "                \"handle_chinese_chars\": false,\n",
    "                \"strip_accents\": false,\n",
    "                \"lowercase\": false\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"pre_tokenizer\": {\n",
    "        \"type\": \"Sequence\",\n",
    "        \"pretokenizers\": [\n",
    "            {\n",
    "                \"type\": \"Metaspace\",\n",
    "                \"replacement\": \"▁\",\n",
    "                \"add_prefix_space\": true\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"post_processor\": null,\n",
    "    \"decoder\": {\n",
    "        \"type\": \"Metaspace\",\n",
    "        \"replacement\": \"▁\",\n",
    "        \"add_prefix_space\": true\n",
    "    },\n",
    "```\n",
    "\n",
    "in `tokenizer_config.json`  \n",
    "```json\n",
    ",\n",
    "    \"model_type\": \"gpt2\"\n",
    "```\n",
    "\n",
    "rename `tokenizer_config.json` => `config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoGNfMvAFH8T",
    "outputId": "a6c3a4a2-43d7-4b35-f4f8-93c4aee75e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2782, 2568, 5271, 4714, 9027, 5190, 18833], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "본 고안은 이러한 특성을 이용해 사용한다\n"
     ]
    }
   ],
   "source": [
    "t = AutoTokenizer.from_pretrained(\"tokenizer\")\n",
    "\n",
    "\n",
    "e = t(\"본 고안은 이러한 특성을 이용해 사용한다.\")\n",
    "print(e)\n",
    "print(t.decode(e['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HoCW3M3_HeeV",
    "M78kc0QyHjW6",
    "ETFAiEUiHgrG"
   ],
   "name": "evolved_transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
