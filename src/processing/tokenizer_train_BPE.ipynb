{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:12:36.479892Z",
     "start_time": "2022-02-28T01:12:35.227082Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:12:36.485386Z",
     "start_time": "2022-02-28T01:12:36.481175Z"
    },
    "id": "ahc_PV2F4WxX"
   },
   "outputs": [],
   "source": [
    "def dump_jsonl(data, output_path, append=False):\n",
    "    mode = \"a+\" if append else \"w\"\n",
    "    with open(output_path, mode, encoding=\"utf-8\") as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + \"\\n\")\n",
    "\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    data = []\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip(\"\\n|\\r\")))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:12:36.497827Z",
     "start_time": "2022-02-28T01:12:36.486677Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 24000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoCW3M3_HeeV"
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:12:37.771776Z",
     "start_time": "2022-02-28T01:12:37.767873Z"
    }
   },
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    text = re.sub(r' +', r' ', text.strip())\n",
    "    text = re.sub(r'(.{8,}?)\\1+', r'\\1', text)\n",
    "    text = re.sub(r'[^ ㄱ-ㅎㅏ-ㅣ가-힣A-Za-z0-9~!@#$%\\^\\&*\\(\\)_\\+\\-=\\[\\]{},\\./<>\\?]', r'', text)\n",
    "    text = re.sub(r'http.+', r'<url>', text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.304276Z",
     "start_time": "2022-02-28T01:12:38.456814Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_jsonl('../../data/category.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.316556Z",
     "start_time": "2022-02-28T01:13:22.305819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'김영환 전 더불어민주당 의원은 16일 문재인 정부의 탈원전 정책에 대해 과학적으로 우매하고 우물 안 개구리 같은 매국적이고 시대착오적 정책이라며 철회를 요구했다 김 전 의원은 김대중 정부 시절 과학기술부 장관을 지냈다 김 전 의원은 민주당 소속으로 4선 의원을 지냈지만 2016년 민주당을 탈당해 국민의당으로 당적을 옮긴 뒤 미래통합당 최고위원을 지냈다김 전 의원은 이날 자신의 페이스북에 글을 올려 청와대 만찬에서 송영길 대표의 목소리를 들으니 벌거벗은 임금님 앞에서 역린을 건드리지 않기 위해 몸을 사리는 신하의 모습이 역력했다며 누구 하나 임금님께서 옷을 벗고 계시다는 것을 말하는 이가 없다고 했다앞서 송영길 민주당 대표는 지난 14일 청와대에서 열린 문 대통령과의 간담회에서 미국 바이든 정부가 탄소중립화를 위해 SMR 분야를 전문 연구하고 있고 중국러시아가 지배하는 원전 시장에 대해 SMR 분야 등 한미 간 전략적 협력을 통해 견제할 필요가 있다며 정부의 정부 탈원전 기조와 반대되는 SMR 연구 필요성을 언급했다김 전 의원은 겨우 SMR를 허용해달라는 말조차 꺼내기가 어려워 진땀을 흘렸다며 정부의 탈원전 정책을 철회해야 한다는 말을 꺼내지도 못하고 변죽만 울렸다고 했다그는 탈원전은 정치권의 무지의 용기 대통령의 오기의 정치가 만든 대참사라며 이 대참사의 폐해는 우리 후손들에게 엄청난 대가로 남아 젊은이들에게 무거운 짐을 지우게 될 것이라고 했다김 전 의원은 체코와 카자흐스탄에서 원전 세일즈 외교를 한 문 대통령을 향해 우리가 먹어보니 독이 든 약인데 당신들도 한번 드셔 보시죠하는 것이냐 우리는 부숴버리면서 왜 아랍에미리트에는 원전을 수출하고 완공을 축하하느냐고 되물었다그는 탈원전이 필요한 이유로 2050년까지 온실가스를 줄이고 탄소제로를 달성해야 하는데 원전 없이는 불가능하고 세계적인 그린 수소 전쟁을 위해 SMR이 절대적으로 필요하며 고준위 핵폐기물 처리 기술의 큰 진전 등을 꼽았다그러면서 탈원전이라는 미친 정책으로 세계 1위 한국형 원전의 생태계가 밑둥부터 허물어졌다며 세계의 흐름을 잘못 읽고 쇄국의 길을 감으로서 망국의 한을 남긴 조상들의 길을 따라가고 있다고 했다      변형'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.340944Z",
     "start_time": "2022-02-28T01:13:22.328315Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAlRbHul7TZ4",
    "outputId": "1a1c971d-474d-40bc-fccb-d3d6c28780b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>',\n",
      " '<unk>',\n",
      " '<cls>',\n",
      " '<sep>',\n",
      " '<mask>',\n",
      " '<bos>',\n",
      " '<eos>',\n",
      " '<tsep>',\n",
      " '<name>',\n",
      " '<url>',\n",
      " '<unk0>',\n",
      " '<unk1>',\n",
      " '<unk2>',\n",
      " '<unk3>',\n",
      " '<unk4>',\n",
      " '<unk5>',\n",
      " '<unk6>',\n",
      " '<unk7>',\n",
      " '<unk8>',\n",
      " '<unk9>',\n",
      " '<unused0>',\n",
      " '<unused1>',\n",
      " '<unused2>',\n",
      " '<unused3>',\n",
      " '<unused4>',\n",
      " '<unused5>',\n",
      " '<unused6>',\n",
      " '<unused7>',\n",
      " '<unused8>',\n",
      " '<unused9>',\n",
      " '<unused10>',\n",
      " '<unused11>',\n",
      " '<unused12>',\n",
      " '<unused13>',\n",
      " '<unused14>',\n",
      " '<unused15>',\n",
      " '<unused16>',\n",
      " '<unused17>',\n",
      " '<unused18>',\n",
      " '<unused19>',\n",
      " '<unused20>',\n",
      " '<unused21>',\n",
      " '<unused22>',\n",
      " '<unused23>',\n",
      " '<unused24>',\n",
      " '<unused25>',\n",
      " '<unused26>',\n",
      " '<unused27>',\n",
      " '<unused28>',\n",
      " '<unused29>',\n",
      " '<unused30>',\n",
      " '<unused31>',\n",
      " '<unused32>',\n",
      " '<unused33>',\n",
      " '<unused34>',\n",
      " '<unused35>',\n",
      " '<unused36>',\n",
      " '<unused37>',\n",
      " '<unused38>',\n",
      " '<unused39>',\n",
      " '<unused40>',\n",
      " '<unused41>',\n",
      " '<unused42>',\n",
      " '<unused43>',\n",
      " '<unused44>',\n",
      " '<unused45>',\n",
      " '<unused46>',\n",
      " '<unused47>',\n",
      " '<unused48>',\n",
      " '<unused49>',\n",
      " '<unused50>',\n",
      " '<unused51>',\n",
      " '<unused52>',\n",
      " '<unused53>',\n",
      " '<unused54>',\n",
      " '<unused55>',\n",
      " '<unused56>',\n",
      " '<unused57>',\n",
      " '<unused58>',\n",
      " '<unused59>',\n",
      " '<unused60>',\n",
      " '<unused61>',\n",
      " '<unused62>',\n",
      " '<unused63>',\n",
      " '<unused64>',\n",
      " '<unused65>',\n",
      " '<unused66>',\n",
      " '<unused67>',\n",
      " '<unused68>',\n",
      " '<unused69>',\n",
      " '<unused70>',\n",
      " '<unused71>',\n",
      " '<unused72>',\n",
      " '<unused73>',\n",
      " '<unused74>',\n",
      " '<unused75>',\n",
      " '<unused76>',\n",
      " '<unused77>',\n",
      " '<unused78>',\n",
      " '<unused79>',\n",
      " '<unused80>',\n",
      " '<unused81>',\n",
      " '<unused82>',\n",
      " '<unused83>',\n",
      " '<unused84>',\n",
      " '<unused85>',\n",
      " '<unused86>',\n",
      " '<unused87>',\n",
      " '<unused88>',\n",
      " '<unused89>',\n",
      " '<unused90>',\n",
      " '<unused91>',\n",
      " '<unused92>',\n",
      " '<unused93>',\n",
      " '<unused94>',\n",
      " '<unused95>',\n",
      " '<unused96>',\n",
      " '<unused97>',\n",
      " '<unused98>',\n",
      " '<unused99>']\n"
     ]
    }
   ],
   "source": [
    "user_defined_symbols = [\"<pad>\", \"<unk>\", \"<cls>\", \"<sep>\", \"<mask>\", \"<bos>\", \"<eos>\", \"<tsep>\", \"<name>\", \"<url>\"]\n",
    "user_defined_symbols += [\"<unk0>\", \"<unk1>\", \"<unk2>\", \"<unk3>\", \"<unk4>\", \"<unk5>\", \"<unk6>\", \"<unk7>\", \"<unk8>\", \"<unk9>\"]\n",
    "unused_token_num = 100\n",
    "unused_list = [f\"<unused{i}>\" for i in range(unused_token_num)]\n",
    "user_defined_symbols += unused_list\n",
    "\n",
    "pprint(user_defined_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M78kc0QyHjW6"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.348724Z",
     "start_time": "2022-02-28T01:13:22.342220Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.354422Z",
     "start_time": "2022-02-28T01:13:22.349991Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFKC, BertNormalizer\n",
    "\n",
    "\n",
    "n1 = NFKC()\n",
    "n2 = BertNormalizer(\n",
    "    clean_text=False,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=False,\n",
    ")\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence([n1, n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.360077Z",
     "start_time": "2022-02-28T01:13:22.355573Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers.pre_tokenizers import Metaspace\n",
    "\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [\n",
    "        Metaspace(\n",
    "            replacement=\"_\",\n",
    "            add_prefix_space=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:13:22.365435Z",
     "start_time": "2022-02-28T01:13:22.361230Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for row in data:\n",
    "        yield processing(row['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:22:35.743895Z",
     "start_time": "2022-02-28T01:13:22.366581Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size, \n",
    "    special_tokens=user_defined_symbols,\n",
    ")\n",
    "tokenizer.train_from_iterator(gen(), trainer)\n",
    "tokenizer.model.save(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:22:35.756300Z",
     "start_time": "2022-02-28T01:22:35.750196Z"
    }
   },
   "outputs": [],
   "source": [
    "output = tokenizer.encode(\"본 고안은 이러한 특성을 이용해 사용한다.\")\n",
    "print(output.ids)\n",
    "\n",
    "tokenizer.decode(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:22:35.768665Z",
     "start_time": "2022-02-28T01:22:35.757686Z"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import decoders\n",
    "\n",
    "tokenizer.decoder = decoders.BPEDecoder(suffix='_')\n",
    "tokenizer.decode(output.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETFAiEUiHgrG"
   },
   "source": [
    "# convert transformers tokenizer and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:28:21.924185Z",
     "start_time": "2022-02-28T01:28:21.920249Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "fast_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:28:24.020021Z",
     "start_time": "2022-02-28T01:28:24.012699Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8RmIRpxgnfJ",
    "outputId": "d31adf46-3539-47de-ea74-6e126751e78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.pad_token = \"<pad>\"\n",
    "fast_tokenizer.unk_token = \"<unk>\"\n",
    "fast_tokenizer.cls_token = \"<cls>\"\n",
    "fast_tokenizer.sep_token = \"<sep>\"\n",
    "fast_tokenizer.mask_token = \"<mask>\"\n",
    "fast_tokenizer.bos_token = \"<bos>\"\n",
    "fast_tokenizer.eos_token = \"<eos>\"\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': user_defined_symbols}\n",
    "fast_tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:28:29.453623Z",
     "start_time": "2022-02-28T01:28:27.519953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 10:28:27.659585: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'테스트용으로 잘 되는지 보고이따'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.decode(fast_tokenizer.encode(\"본 고안은 이러한 특성을 이용하여 사용한다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T01:28:54.551802Z",
     "start_time": "2022-02-28T01:28:54.470879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('etc/DialogBPETokenizer/tokenizer_config.json',\n",
       " 'etc/DialogBPETokenizer/special_tokens_map.json',\n",
       " 'etc/DialogBPETokenizer/vocab.json',\n",
       " 'etc/DialogBPETokenizer/merges.txt',\n",
       " 'etc/DialogBPETokenizer/added_tokens.json',\n",
       " 'etc/DialogBPETokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.save_pretrained(\"tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HoCW3M3_HeeV",
    "M78kc0QyHjW6",
    "ETFAiEUiHgrG"
   ],
   "name": "evolved_transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
